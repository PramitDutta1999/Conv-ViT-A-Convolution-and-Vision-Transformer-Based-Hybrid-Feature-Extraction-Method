# Conv-ViT-A-Convolution-and-Vision-Transformer-Based-Hybrid-Feature-Extraction-Method

This project implements Conv-ViT, a hybrid deep learning architecture combining convolutional neural networks (CNNs) and Vision Transformers (ViTs) for effective retinal disease classification using Optical Coherence Tomography (OCT) images.

## Overview
Conv-ViT leverages the texture-learning capabilities of CNNs (Inception-V3 and ResNet-50) and the global feature extraction power of Vision Transformers to enhance OCT image classification. The model classifies images into four categories: CNV, DME, Drusen, and Normal.
**This work was conducted as part of my undergraduate thesis project. You can [read the full thesis here]([https://your-thesis-link.com](https://www.researchgate.net/publication/372343833_CONV-VIT_A_CONVOLUTION_AND_VISION_TRANSFORMER_BASED_HYBRID_FEATURE_EXTRACTION_METHOD_FOR_RETINAL_DISEASE_DETECTION)).**

## Key Features
-Hybrid architecture combining CNN and ViT

-Enhanced feature extraction from OCT images

-Achieves ~94% accuracy on standard datasets

-Applied to real-world retinal disease classification

## Dataset
The model was trained and tested on a publicly available OCT dataset containing labeled images for CNV, DME, Drusen, and Normal classes.

## How to Use
01. Open in Colab: Click the button below to launch the notebook in Google Colab:

02. Run All Cells: Follow the cells step-by-step. All dependencies are automatically installed, and the code is fully compatible with Colab.

03. Adjust File Paths: Update file paths in code cells accordingly.

## Reference

This work was published as: *Conv-ViT: A Convolution and Vision Transformer-Based Hybrid Feature Extraction Method for Retinal OCT Classification*  [Read the full paper here](https://www.mdpi.com/2313-433X/9/7/140)

If you use this code or model in your research, please cite the paper to acknowledge the original work.
